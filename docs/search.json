[
  {
    "objectID": "lab/lab_1/lab1_template.html",
    "href": "lab/lab_1/lab1_template.html",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the ** State of Washington Department of Human Services**. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.\n\n\n\n\nApply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders\n\n\n\n\nSubmit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/labs/lab_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Labs” menu."
  },
  {
    "objectID": "lab/lab_1/lab1_template.html#scenario",
    "href": "lab/lab_1/lab1_template.html#scenario",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the ** State of Washington Department of Human Services**. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues."
  },
  {
    "objectID": "lab/lab_1/lab1_template.html#learning-objectives",
    "href": "lab/lab_1/lab1_template.html#learning-objectives",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Apply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders"
  },
  {
    "objectID": "lab/lab_1/lab1_template.html#submission-instructions",
    "href": "lab/lab_1/lab1_template.html#submission-instructions",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Submit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/labs/lab_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Labs” menu."
  },
  {
    "objectID": "lab/lab_1/lab1_template.html#data-retrieval",
    "href": "lab/lab_1/lab1_template.html#data-retrieval",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.1 Data Retrieval",
    "text": "2.1 Data Retrieval\nYour Task: Use get_acs() to retrieve county-level data for your chosen state.\nRequirements: - Geography: county level - Variables: median household income (B19013_001) and total population (B01003_001)\n- Year: 2022 - Survey: acs5 - Output format: wide\nHint: Remember to give your variables descriptive names using the variables = c(name = \"code\") syntax.\n\n# Write your get_acs() code here\nWA_data &lt;- get_acs(\n  geography = \"county\",\n  variables = c(\n    tot_pop = \"B01003_001\", \n    med_hh_inc = \"B19013_001\"\n  ), \n  year = 2022,\n  survey = \"acs5\",\n  state = \"WA\", \n  output = \"wide\"\n)\n print(WA_data)\n\n# A tibble: 39 × 6\n   GEOID NAME                        tot_popE tot_popM med_hh_incE med_hh_incM\n   &lt;chr&gt; &lt;chr&gt;                          &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 53001 Adams County, Washington       20557       NA       63105        3509\n 2 53003 Asotin County, Washington      22370       NA       63724        6045\n 3 53005 Benton County, Washington     207560       NA       83778        1849\n 4 53007 Chelan County, Washington      79076       NA       71876        4147\n 5 53009 Clallam County, Washington     77333       NA       66108        2368\n 6 53011 Clark County, Washington      504091       NA       90115        1650\n 7 53013 Columbia County, Washington     3980       NA       68825        4234\n 8 53015 Cowlitz County, Washington    110621       NA       70912        2483\n 9 53017 Douglas County, Washington     43189       NA       79422        2924\n10 53019 Ferry County, Washington        7260       NA       50424        4642\n# ℹ 29 more rows\n\n# Makes analysis easier\n\n# Clean the county names to remove state name and \"County\" \n# Hint: use mutate() with str_remove()\nWA_clean &lt;- WA_data %&gt;%\n  mutate(\n    county_name = str_remove(NAME, \", Washington\"),\n    county_name = str_remove(county_name, \"County\")\n  )\n\n \n head(WA_clean)\n\n# A tibble: 6 × 7\n  GEOID NAME               tot_popE tot_popM med_hh_incE med_hh_incM county_name\n  &lt;chr&gt; &lt;chr&gt;                 &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;      \n1 53001 Adams County, Was…    20557       NA       63105        3509 \"Adams \"   \n2 53003 Asotin County, Wa…    22370       NA       63724        6045 \"Asotin \"  \n3 53005 Benton County, Wa…   207560       NA       83778        1849 \"Benton \"  \n4 53007 Chelan County, Wa…    79076       NA       71876        4147 \"Chelan \"  \n5 53009 Clallam County, W…    77333       NA       66108        2368 \"Clallam \" \n6 53011 Clark County, Was…   504091       NA       90115        1650 \"Clark \"   \n\n# Display the first few rows"
  },
  {
    "objectID": "lab/lab_1/lab1_template.html#data-quality-assessment",
    "href": "lab/lab_1/lab1_template.html#data-quality-assessment",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.2 Data Quality Assessment",
    "text": "2.2 Data Quality Assessment\nYour Task: Calculate margin of error percentages and create reliability categories.\nRequirements: - Calculate MOE percentage: (margin of error / estimate) * 100 - Create reliability categories: - High Confidence: MOE &lt; 5% - Moderate Confidence: MOE 5-10%\n- Low Confidence: MOE &gt; 10% - Create a flag for unreliable estimates (MOE &gt; 10%)\nHint: Use mutate() with case_when() for the categories.\n\n# Calculate MOE percentage and reliability categories using mutate()\nWA_reliability &lt;- WA_clean %&gt;%\n  mutate(\n    MOE_pct = round((med_hh_incM / med_hh_incE) * 100,2), \n    reliability = case_when(\n      MOE_pct &lt; 5 ~ \"High Confidence\",\n      MOE_pct &gt;= 5 & MOE_pct &lt;= 10 ~ \"Moderate Confidence\",\n      MOE_pct &gt; 10 ~ \"Low Confidence\"\n    )\n  )\n\nglimpse(WA_reliability)\n\nRows: 39\nColumns: 9\n$ GEOID       &lt;chr&gt; \"53001\", \"53003\", \"53005\", \"53007\", \"53009\", \"53011\", \"530…\n$ NAME        &lt;chr&gt; \"Adams County, Washington\", \"Asotin County, Washington\", \"…\n$ tot_popE    &lt;dbl&gt; 20557, 22370, 207560, 79076, 77333, 504091, 3980, 110621, …\n$ tot_popM    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ med_hh_incE &lt;dbl&gt; 63105, 63724, 83778, 71876, 66108, 90115, 68825, 70912, 79…\n$ med_hh_incM &lt;dbl&gt; 3509, 6045, 1849, 4147, 2368, 1650, 4234, 2483, 2924, 4642…\n$ county_name &lt;chr&gt; \"Adams \", \"Asotin \", \"Benton \", \"Chelan \", \"Clallam \", \"Cl…\n$ MOE_pct     &lt;dbl&gt; 5.56, 9.49, 2.21, 5.77, 3.58, 1.83, 6.15, 3.50, 3.68, 9.21…\n$ reliability &lt;chr&gt; \"Moderate Confidence\", \"Moderate Confidence\", \"High Confid…\n\n head(WA_data)\n\n# A tibble: 6 × 6\n  GEOID NAME                       tot_popE tot_popM med_hh_incE med_hh_incM\n  &lt;chr&gt; &lt;chr&gt;                         &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1 53001 Adams County, Washington      20557       NA       63105        3509\n2 53003 Asotin County, Washington     22370       NA       63724        6045\n3 53005 Benton County, Washington    207560       NA       83778        1849\n4 53007 Chelan County, Washington     79076       NA       71876        4147\n5 53009 Clallam County, Washington    77333       NA       66108        2368\n6 53011 Clark County, Washington     504091       NA       90115        1650\n\n #Identify counties with higher uncertainty based on MOE percent\n \n high_uncertainty &lt;- WA_reliability %&gt;%\n  filter(MOE_pct &gt; 10) %&gt;%\n  arrange(desc(MOE_pct)) %&gt;%\n  select(county_name,med_hh_incE, MOE_pct)\n \n# Create a summary showing count of counties in each reliability category\n # Hint: use count() and mutate() to add percentages\n \nrel_summary &lt;- WA_reliability %&gt;%\n  group_by (reliability) %&gt;%\n  summarize(\n    counties = n(), \n  )\n\n\nprint(rel_summary)\n\n# A tibble: 3 × 2\n  reliability         counties\n  &lt;chr&gt;                  &lt;int&gt;\n1 High Confidence           21\n2 Low Confidence             3\n3 Moderate Confidence       15\n\n#Table   \n \n kable(rel_summary,\n      col.names = c(\"Reliability\", \"Count of Counties\"),\n      caption = \"Counties with Highest Income Data Uncertainty\",\n      format.args = list(big.mark = \",\"))\n\n\nCounties with Highest Income Data Uncertainty\n\n\nReliability\nCount of Counties\n\n\n\n\nHigh Confidence\n21\n\n\nLow Confidence\n3\n\n\nModerate Confidence\n15"
  },
  {
    "objectID": "lab/lab_1/lab1_template.html#high-uncertainty-counties",
    "href": "lab/lab_1/lab1_template.html#high-uncertainty-counties",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.3 High Uncertainty Counties",
    "text": "2.3 High Uncertainty Counties\nYour Task: Identify the 5 counties with the highest MOE percentages.\nRequirements: - Sort by MOE percentage (highest first) - Select the top 5 counties - Display: county name, median income, margin of error, MOE percentage, reliability category - Format as a professional table using kable()\nHint: Use arrange(), slice(), and select() functions.\n\n# Create table of top 5 counties by MOE percentage\n\nhigh_uncertainty_top5 &lt;- WA_reliability %&gt;%\n  arrange(desc(MOE_pct)) %&gt;%\n  slice(1:5) %&gt;%\n  select(county_name, med_hh_incE, med_hh_incM, MOE_pct, reliability)\n\n# Format as table with kable()\nkable(high_uncertainty_top5,\n      col.names = c(\"County\", \"Median Income\", \"Margin of Error (MOE)\", \"MOE %\", \"Reliability\"),\n      caption = \"Top 5 Counties with Highest Income Data Uncertainty\",\n      digits = 2,\n      format.args = list(big.mark = \",\"))\n\n\nTop 5 Counties with Highest Income Data Uncertainty\n\n\n\n\n\n\n\n\n\nCounty\nMedian Income\nMargin of Error (MOE)\nMOE %\nReliability\n\n\n\n\nGarfield\n57,958\n13,662\n23.57\nLow Confidence\n\n\nWahkiakum\n59,167\n7,057\n11.93\nLow Confidence\n\n\nPend Oreille\n59,353\n6,485\n10.93\nLow Confidence\n\n\nAsotin\n63,724\n6,045\n9.49\nModerate Confidence\n\n\nFerry\n50,424\n4,642\n9.21\nModerate Confidence\n\n\n\n\n# Format as table with kable() - include appropriate column names and caption\n\nData Quality Commentary:\nCounties like Garfield, Wahkiakum, and Pend Oreille all have Low Confidence and are most at risk of being poorly served by algorithms that may use this data. This is concerning because, with the MOE exceeding 10%, estimates could deviate significantly from the actual values. These counties are likely small and rural, resulting in higher uncertainty. An algorithm that treats these uncertain estimates with the same confidence as high-reliability counties could improperly allocate needed funding by either overlooking communities that truly need it, or even directing resources inaccurately."
  },
  {
    "objectID": "lab/lab_1/lab1_template.html#focus-area-selection",
    "href": "lab/lab_1/lab1_template.html#focus-area-selection",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.1 Focus Area Selection",
    "text": "3.1 Focus Area Selection\nYour Task: Select 2-3 counties from your reliability analysis for detailed tract-level study.\nStrategy: Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.\n\n# Use filter() to select 2-3 counties from your county_reliability data\n# Store the selected counties in a variable called selected_counties\n#note to self: %in% tells filter to check for values in a list\n\nselected_counties &lt;- WA_reliability %&gt;%\n  filter(county_name %in% c(\"King \", \"Asotin \", \"Garfield \")) %&gt;%\n  select(county_name, med_hh_incE, MOE_pct, reliability)\n\n\n# Display the selected counties with their key characteristics\n# Show: county name, median income, MOE percentage, reliability category\nkable(selected_counties,\n      col.names = c(\"County\", \"Median Income\", \"MOE %\", \"Reliability\"),\n      caption = \"Selected Counties for Tract-Level Analysis\",\n      digits = 2,\n      format.args = list(big.mark = \",\"))\n\n\nSelected Counties for Tract-Level Analysis\n\n\nCounty\nMedian Income\nMOE %\nReliability\n\n\n\n\nAsotin\n63,724\n9.49\nModerate Confidence\n\n\nGarfield\n57,958\n23.57\nLow Confidence\n\n\nKing\n116,340\n0.74\nHigh Confidence"
  },
  {
    "objectID": "lab/lab_1/lab1_template.html#tract-level-demographics",
    "href": "lab/lab_1/lab1_template.html#tract-level-demographics",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.2 Tract-Level Demographics",
    "text": "3.2 Tract-Level Demographics\nYour Task: Get demographic data for census tracts in your selected counties.\nRequirements: - Geography: tract level - Variables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001) - Use the same state and year as before - Output format: wide - Challenge: You’ll need county codes, not names. Look at the GEOID patterns in your county data for hints.\n\n# Define your race/ethnicity variables with descriptive names\n# Use get_acs() to retrieve tract-level data\n# Hint: You may need to specify county codes in the county parameter\n\nWA_demographics &lt;- get_acs(\n  geography = \"tract\",\n  variables = c(\n    total_pop = \"B03002_001\",\n    white = \"B03002_003\",\n    black = \"B03002_004\",\n    hispanic = \"B03002_012\"\n  ),\n  state = \"WA\",\n  county = c(\"053\", \"023\", \"033\"),\n  year = 2022,\n  survey = \"acs5\",\n  output = \"wide\"\n)\n\nhead(WA_demographics)\n\n# A tibble: 6 × 10\n  GEOID       NAME   total_popE total_popM whiteE whiteM blackE blackM hispanicE\n  &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n1 53023970300 Censu…       2310         NA   2051    112     22     25        87\n2 53033000101 Censu…       3399        590   1557    604    519    221       293\n3 53033000102 Censu…       4382        797   3294    708    155    150       328\n4 53033000201 Censu…       4691        706   2747    592    560    401       538\n5 53033000202 Censu…       4425        552   2278    310    433    326       583\n6 53033000300 Censu…       2964        361   1886    384     60     78       107\n# ℹ 1 more variable: hispanicM &lt;dbl&gt;\n\n# Calculate percentage of each group using mutate()\n# Create percentages for white, Black, and Hispanic populations\n\nWA_demographics &lt;- WA_demographics %&gt;%\n  mutate(\n    pct_white = (whiteE/total_popE)*100, \n    pct_black = (blackE/total_popE) *100,\n    pct_hispanic = (hispanicE /total_popE) *100\n  )\n\n# Add readable tract and county name columns using str_extract() or similar\nWA_demographics &lt;- WA_demographics %&gt;%\n  mutate(\n    tract_name = str_remove(NAME, \"Census Tract \") %&gt;%\n                 str_remove(\"; Washington\")\n  )\n\nNotes output (wide) = one variable per row str_remove() — want to delete part of it str_extract() — to pull out a specific piece from the string"
  },
  {
    "objectID": "lab/lab_1/lab1_template.html#demographic-analysis",
    "href": "lab/lab_1/lab1_template.html#demographic-analysis",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.3 Demographic Analysis",
    "text": "3.3 Demographic Analysis\nYour Task: Analyze the demographic patterns in your selected areas.\n\n# Find the tract with the highest percentage of Hispanic/Latino residents\n# Hint: use arrange() and slice() to get the top tract\n\n# Tract with highest percentage of Hispanic/Latino residents\ntop_hisp &lt;- WA_demographics %&gt;%\n  arrange(desc(pct_hispanic)) %&gt;%\n  slice(1) %&gt;%\n  select(tract_name, pct_hispanic)\n\nprint(top_hisp)\n\n# A tibble: 1 × 2\n  tract_name          pct_hispanic\n  &lt;chr&gt;                      &lt;dbl&gt;\n1 308.01; King County         52.2\n\n# Average demographics by county..Code for extract from AI\n\n  WA_demographics &lt;- WA_demographics %&gt;%\n  mutate(county_name = str_extract(NAME, \"[A-Za-z ]+County\"))\n  \ncounty_avg &lt;- WA_demographics %&gt;%\n  group_by(county_name) %&gt;%\n  summarize(\n    num_tracts = n(),\n    avg_pct_white = round(mean(pct_white, na.rm = TRUE), 2),\n    avg_pct_black = round(mean(pct_black, na.rm = TRUE), 2),\n    avg_pct_hispanic = round(mean(pct_hispanic, na.rm = TRUE), 2)\n  )\n\nkable(county_avg,\n      col.names = c(\"County\", \"Count of Tracts\", \"Avg % White\", \"Avg % Black\", \"Avg % Hispanic\"),\n      caption = \"Average Demographics by County\",\n      digits = 2,\n      format.args = list(big.mark = \",\"))\n\n\nAverage Demographics by County\n\n\n\n\n\n\n\n\n\nCounty\nCount of Tracts\nAvg % White\nAvg % Black\nAvg % Hispanic\n\n\n\n\nGarfield County\n1\n88.79\n0.95\n3.77\n\n\nKing County\n495\n56.31\n6.34\n9.81\n\n\nPierce County\n193\n63.66\n6.90\n11.82\n\n\n\n\n# Calculate average demographics by county using group_by() and summarize()\n# Show: number of tracts, average percentage for each racial/ethnic group\n\n# Create a nicely formatted table of your results using kable()"
  },
  {
    "objectID": "lab/lab_1/lab1_template.html#moe-analysis-for-demographic-variables",
    "href": "lab/lab_1/lab1_template.html#moe-analysis-for-demographic-variables",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "4.1 MOE Analysis for Demographic Variables",
    "text": "4.1 MOE Analysis for Demographic Variables\nYour Task: Examine margins of error for demographic variables to see if some communities have less reliable data.\nRequirements: - Calculate MOE percentages for each demographic variable - Flag tracts where any demographic variable has MOE &gt; 15% - Create summary statistics\n\n# Calculate MOE percentages for white, Black, and Hispanic variables\n# Hint: use the same formula as before (margin/estimate * 100)\nMOE_WA_demographics &lt;- WA_demographics %&gt;%\n mutate(\n   MOE_pct_White = (whiteM/whiteE) *100, \n   MOE_pct_Black = (blackM/blackE)*100, \n   MOE_pct_Hispanic= (hispanicM/hispanicE)*100\n\n )\n# Create a flag for tracts with high MOE on any demographic variable\n# Use logical operators (| for OR) in an ifelse() statement\n\nMOE_WA_demographics &lt;- MOE_WA_demographics %&gt;%\n  mutate(MOE_flag = ifelse(MOE_pct_White &gt; 15 | MOE_pct_Black &gt; 15 | MOE_pct_Hispanic &gt; 15, \"Yes\", \"No\"))\n\n# Create summary statistics showing how many tracts have data quality issues\nMOE_WA_demographics %&gt;%\n  group_by(MOE_flag) %&gt;%\n  summarize(\n    num_tracts = n()\n  )\n\n# A tibble: 1 × 2\n  MOE_flag num_tracts\n  &lt;chr&gt;         &lt;int&gt;\n1 Yes             689"
  },
  {
    "objectID": "lab/lab_1/lab1_template.html#pattern-analysis",
    "href": "lab/lab_1/lab1_template.html#pattern-analysis",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "4.2 Pattern Analysis",
    "text": "4.2 Pattern Analysis\nYour Task: Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.\n\n# Group tracts by whether they have high MOE issues\n# Calculate average characteristics for each group:\n# - population size, demographic percentages\n\npattern_analysis &lt;- MOE_WA_demographics %&gt;%\n  group_by(MOE_flag) %&gt;%\n  summarize(\n    num_tracts = n(),\n    avg_population = round(mean(total_popE, na.rm = TRUE), 0),\n    avg_pct_white = round(mean(pct_white, na.rm = TRUE), 2),\n    avg_pct_black = round(mean(pct_black, na.rm = TRUE), 2),\n    avg_pct_hispanic = round(mean(pct_hispanic, na.rm = TRUE), 2)\n  )\n\nkable(pattern_analysis,\n      col.names = c(\"High MOE Flag\", \"Number of Tracts\", \"Avg Population\", \"Avg % White\", \"Avg % Black\", \"Avg % Hispanic\"),\n      caption = \"Data Patterns by Tract Characteristics\",\n      digits = 2,\n      format.args = list(big.mark = \",\"))\n\n\nData Patterns by Tract Characteristics\n\n\n\n\n\n\n\n\n\n\nHigh MOE Flag\nNumber of Tracts\nAvg Population\nAvg % White\nAvg % Black\nAvg % Hispanic\n\n\n\n\nYes\n689\n4,609\n58.42\n6.49\n10.37\n\n\n\n\n# Use group_by() and summarize() to create this comparison\n# Create a professional table showing the patterns\n\nPattern Analysis: This table shows an interesting pattern, if we can call it a pattern at all. The pattern analysis shows that all 689 census tracts in Washington State were flagged for high MOE on at least one variable (White, Black, or Hispanic), indicating that data quality issues are widepread across the state instead of being isolated to particular areas. The table shows very small shares of non-white populations; when a tract has very few Black or Hispanic residents, even a small absolute MOE could be reflected as a large percentage, making the 15% threshold we set very difficult or even impossible to meet across Washington’s predominantly white communities.\nWhen we consider equity issues that could arise from algorithmic bias, it is very important to consider if the thresholds we apply are considerate of the demopgraphic make-up in the tracts. What counts as unreliable data for a majority minority urban tract will end up being very different from what it means for a rural predominantly white one. In future analyses, it would be more equitable to explore MOE thresholds that are specific to population size, and demographic make-up."
  },
  {
    "objectID": "lab/lab_1/lab1_template.html#analysis-integration-and-professional-summary",
    "href": "lab/lab_1/lab1_template.html#analysis-integration-and-professional-summary",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "5.1 Analysis Integration and Professional Summary",
    "text": "5.1 Analysis Integration and Professional Summary\nYour Task: Write an executive summary that integrates findings from all four analyses.\nExecutive Summary Requirements: 1. Overall Pattern Identification: What are the systematic patterns across all your analyses?\nAcross all four analyses, there is a consistent pattern where data reliability in Washington State is quite uneven and seemingly tied to population size. County-level income data shopwed that that the least reliable estimates (MOE % &gt; 10%) are concentrated in smaller rural counties like Garfield, Wahkiakum, and Pend Oreille. Now diving deeper, at the tract level, this problem is exacerbated further with all 689 tracts flagged for high uncertainty on at least one variable (White, Black, or Hispanic). This show the fragmented reality of estimates with extremely different levels of confidence.\n\nEquity Assessment: Which communities face the greatest risk of algorithmic bias based on your findings?\n\nThe communitiies facing the greatest risk of algorithmic bias tend to be the small rural counties with low and moderate incomes, such as Garfield and Ferry Counties, where data uncertainty is highest. These communities would be most harmed by algorithms that treats uncertain estimates with the same confidence threshold as reliable ones, resulted in misrepresented need for social services and improper distribution of funding as a result. Additionally, minority communities face increasing risk because data is the least statistically confident from small population counts. Therefore, algorithms that use racial breakdowns will probably be working with unreliable information for the communities that would most need equitable representation in policy decisions.\n\nRoot Cause Analysis: What underlying factors drive both data quality issues and bias risk?\n\nThe underlying factor of these data quality issues is merely the nature of the ACS, where, unlike a full census count, the ACS takes a sample the population, which means already-small communities will produce even fewer responses and thus less statistically stable estimates. Evidently, this disadvantages rural and more sparse populations. Further, considering Washington is predominantly white means that Black and Hispanic residents make up very small shares of most tracts, causing MOE percentages to increase substantially.\n\nStrategic Recommendations: What should the Department implement to address these systematic issues?\n\nThe Department of Human Services should not have a uniform algorithmic system without first looking at and analyzing data reliability. To illustrate, high confidence counties like King County might be more appropriate for algorithmic decision-making, but low confidence counties like Garfield should require mandatory human review. If possible and/or feasible, the Department should also look into collecting supplemental data in rural and minority communities, which tends to be regions with weaker estimates. Any MOE thresholds used in future analyses should be based on the demographic and geographic context of each community rather than applied uniformly statewide.\nExecutive Summary:\nAcross all four analyses, data reliability in Washington State has shown to be very uneven. Even more so, it has consistently been tied to population size, with the least reliable estimates in small counties and even higher unreliability at the tract level (all 689 tracts were flagged for high uncertainty). The communities facing the greatest risk of algorithmic bias are small, lower-income rural counties (e.x., Garfield and Ferry), AND minority communities. Clearly, this means any algorithm using racial breakdowns would be using weakest data for communities most in need of equitable representation. Because the ACS is a sample survey rather than a full count, it structurally disadvantages already-small populations and causes MOE percentages for minority groups to increase substantially in a predominantly white state, such as Washington. In response, the Department of Human Services should move away from a uniform algorithmic approach and instead build data reliability directly into decision-making, which includes human-based review initially for low confidence counties. In addition, it would be beneficial to puruse additional data collection of underrepresented communities, while using MOE thresholds specific to demographic and geographical contexts of each community rather than applying a standard statewide."
  },
  {
    "objectID": "lab/lab_1/lab1_template.html#specific-recommendations",
    "href": "lab/lab_1/lab1_template.html#specific-recommendations",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "6.3 Specific Recommendations",
    "text": "6.3 Specific Recommendations\nYour Task: Create a decision framework for algorithm implementation.\n\n# Create a summary table using your county reliability data\n# Include: county name, median income, MOE percentage, reliability category\n\n# Add a new column with algorithm recommendations using case_when():\n# - High Confidence: \"Safe for algorithmic decisions\"\n# - Moderate Confidence: \"Use with caution - monitor outcomes\"  \n# - Low Confidence: \"Requires manual review or additional data\"\n\nfinal_recommendations &lt;- WA_reliability %&gt;%\n  select(county_name, med_hh_incE, MOE_pct, reliability) %&gt;%\n  mutate(algorithm_recommendation = case_when(\n    reliability == \"High Confidence\" ~ \"Safe for algorithmic decisions\",\n    reliability == \"Moderate Confidence\" ~ \"Use with caution - monitor outcomes\",\n    reliability == \"Low Confidence\" ~ \"Requires manual review or additional data\"\n  ))\n\n# Format as a professional table with kable()\n\nkable(final_recommendations,\n      col.names = c(\"County\", \"Median Income\", \"MOE %\", \"Reliability\", \"Algorithm Recommendation\"),\n      caption = \"County-Level Algorithm Implementation Framework\",\n      digits = 2,\n      format.args = list(big.mark = \",\"))\n\n\nCounty-Level Algorithm Implementation Framework\n\n\n\n\n\n\n\n\n\nCounty\nMedian Income\nMOE %\nReliability\nAlgorithm Recommendation\n\n\n\n\nAdams\n63,105\n5.56\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nAsotin\n63,724\n9.49\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nBenton\n83,778\n2.21\nHigh Confidence\nSafe for algorithmic decisions\n\n\nChelan\n71,876\n5.77\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nClallam\n66,108\n3.58\nHigh Confidence\nSafe for algorithmic decisions\n\n\nClark\n90,115\n1.83\nHigh Confidence\nSafe for algorithmic decisions\n\n\nColumbia\n68,825\n6.15\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nCowlitz\n70,912\n3.50\nHigh Confidence\nSafe for algorithmic decisions\n\n\nDouglas\n79,422\n3.68\nHigh Confidence\nSafe for algorithmic decisions\n\n\nFerry\n50,424\n9.21\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nFranklin\n77,877\n5.06\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nGarfield\n57,958\n23.57\nLow Confidence\nRequires manual review or additional data\n\n\nGrant\n66,387\n6.31\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nGrays Harbor\n59,105\n4.72\nHigh Confidence\nSafe for algorithmic decisions\n\n\nIsland\n82,850\n3.55\nHigh Confidence\nSafe for algorithmic decisions\n\n\nJefferson\n64,796\n7.59\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nKing\n116,340\n0.74\nHigh Confidence\nSafe for algorithmic decisions\n\n\nKitsap\n93,675\n2.41\nHigh Confidence\nSafe for algorithmic decisions\n\n\nKittitas\n66,800\n4.50\nHigh Confidence\nSafe for algorithmic decisions\n\n\nKlickitat\n66,581\n7.04\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nLewis\n67,247\n4.11\nHigh Confidence\nSafe for algorithmic decisions\n\n\nLincoln\n68,172\n4.67\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMason\n74,388\n5.43\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nOkanogan\n58,218\n3.72\nHigh Confidence\nSafe for algorithmic decisions\n\n\nPacific\n58,889\n7.01\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nPend Oreille\n59,353\n10.93\nLow Confidence\nRequires manual review or additional data\n\n\nPierce\n91,486\n1.30\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Juan\n76,745\n4.42\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSkagit\n82,029\n2.52\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSkamania\n84,500\n5.85\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nSnohomish\n104,083\n1.28\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSpokane\n70,394\n1.55\nHigh Confidence\nSafe for algorithmic decisions\n\n\nStevens\n62,381\n5.82\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nThurston\n88,895\n2.43\nHigh Confidence\nSafe for algorithmic decisions\n\n\nWahkiakum\n59,167\n11.93\nLow Confidence\nRequires manual review or additional data\n\n\nWalla Walla\n66,635\n6.93\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nWhatcom\n77,581\n3.27\nHigh Confidence\nSafe for algorithmic decisions\n\n\nWhitman\n49,345\n7.54\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nYakima\n64,910\n3.40\nHigh Confidence\nSafe for algorithmic decisions\n\n\n\n\n#Specific breakdown\n\n# High Confidence Counties\nhigh_conf &lt;- final_recommendations %&gt;%\n  filter(reliability == \"High Confidence\") %&gt;%\n  kable(col.names = c(\"County\", \"Median Income\", \"MOE %\", \"Reliability\", \"Recommendation\"),\n        caption = \"Counties Suitable for Algorithmic Implementation\",\n        digits = 2,\n        format.args = list(big.mark = \",\"))\n\n# Moderate Confidence Counties\nmod_conf &lt;- final_recommendations %&gt;%\n  filter(reliability == \"Moderate Confidence\") %&gt;%\n  kable(col.names = c(\"County\", \"Median Income\", \"MOE %\", \"Reliability\", \"Recommendation\"),\n        caption = \"Counties Requiring Additional Oversight\",\n        digits = 2,\n        format.args = list(big.mark = \",\"))\n\n# Low Confidence Counties\nlow_conf &lt;- final_recommendations %&gt;%\n  filter(reliability == \"Low Confidence\") %&gt;%\n  kable(col.names = c(\"County\", \"Median Income\", \"MOE %\", \"Reliability\", \"Recommendation\"),\n        caption = \"Counties Needing Alternative Approaches\",\n        digits = 2,\n        format.args = list(big.mark = \",\"))\n\nhigh_conf\n\n\nCounties Suitable for Algorithmic Implementation\n\n\n\n\n\n\n\n\n\nCounty\nMedian Income\nMOE %\nReliability\nRecommendation\n\n\n\n\nBenton\n83,778\n2.21\nHigh Confidence\nSafe for algorithmic decisions\n\n\nClallam\n66,108\n3.58\nHigh Confidence\nSafe for algorithmic decisions\n\n\nClark\n90,115\n1.83\nHigh Confidence\nSafe for algorithmic decisions\n\n\nCowlitz\n70,912\n3.50\nHigh Confidence\nSafe for algorithmic decisions\n\n\nDouglas\n79,422\n3.68\nHigh Confidence\nSafe for algorithmic decisions\n\n\nGrays Harbor\n59,105\n4.72\nHigh Confidence\nSafe for algorithmic decisions\n\n\nIsland\n82,850\n3.55\nHigh Confidence\nSafe for algorithmic decisions\n\n\nKing\n116,340\n0.74\nHigh Confidence\nSafe for algorithmic decisions\n\n\nKitsap\n93,675\n2.41\nHigh Confidence\nSafe for algorithmic decisions\n\n\nKittitas\n66,800\n4.50\nHigh Confidence\nSafe for algorithmic decisions\n\n\nLewis\n67,247\n4.11\nHigh Confidence\nSafe for algorithmic decisions\n\n\nLincoln\n68,172\n4.67\nHigh Confidence\nSafe for algorithmic decisions\n\n\nOkanogan\n58,218\n3.72\nHigh Confidence\nSafe for algorithmic decisions\n\n\nPierce\n91,486\n1.30\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Juan\n76,745\n4.42\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSkagit\n82,029\n2.52\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSnohomish\n104,083\n1.28\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSpokane\n70,394\n1.55\nHigh Confidence\nSafe for algorithmic decisions\n\n\nThurston\n88,895\n2.43\nHigh Confidence\nSafe for algorithmic decisions\n\n\nWhatcom\n77,581\n3.27\nHigh Confidence\nSafe for algorithmic decisions\n\n\nYakima\n64,910\n3.40\nHigh Confidence\nSafe for algorithmic decisions\n\n\n\n\nmod_conf\n\n\nCounties Requiring Additional Oversight\n\n\n\n\n\n\n\n\n\nCounty\nMedian Income\nMOE %\nReliability\nRecommendation\n\n\n\n\nAdams\n63,105\n5.56\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nAsotin\n63,724\n9.49\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nChelan\n71,876\n5.77\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nColumbia\n68,825\n6.15\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nFerry\n50,424\n9.21\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nFranklin\n77,877\n5.06\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nGrant\n66,387\n6.31\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nJefferson\n64,796\n7.59\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nKlickitat\n66,581\n7.04\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nMason\n74,388\n5.43\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nPacific\n58,889\n7.01\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nSkamania\n84,500\n5.85\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nStevens\n62,381\n5.82\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nWalla Walla\n66,635\n6.93\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nWhitman\n49,345\n7.54\nModerate Confidence\nUse with caution - monitor outcomes\n\n\n\n\nlow_conf\n\n\nCounties Needing Alternative Approaches\n\n\n\n\n\n\n\n\n\nCounty\nMedian Income\nMOE %\nReliability\nRecommendation\n\n\n\n\nGarfield\n57,958\n23.57\nLow Confidence\nRequires manual review or additional data\n\n\nPend Oreille\n59,353\n10.93\nLow Confidence\nRequires manual review or additional data\n\n\nWahkiakum\n59,167\n11.93\nLow Confidence\nRequires manual review or additional data\n\n\n\n\n\nKey Recommendations:\nYour Task: Use your analysis results to provide specific guidance to the department.\n\nCounties suitable for immediate algorithmic implementation: A significant share of the the counties were considered high confidence. King County and other high confidence counties are better fit for algorithmic decision-making because their income estimates carry MOE percentages less than 5%, meaning the data is stable enough to support such automated decisions without any major risk of misallocation.\nCounties requiring additional oversight: Moderate confidence counties like Asotin, Grant, and Jefferson (total of 15 counties), should use algorithms with caution. This could mean having human reviewers periodically auditing outputs to find instances where estimates may be leading to inconsistent or inequitable funding decisions.\nCounties needing alternative approaches: Becasue the threshold used earlier was not updated, there are still only 3 counties (Garfield, Wahkiakum, and Pend Oreille) that would require any sort of human-interaction rather than an algorithm on its own. Instead, the Department should consider, as mentioned earlier, community outreach for supplemental data, or possibly other data (if feasible) from local agencies to build more reliability."
  },
  {
    "objectID": "lab/lab_1/lab1_template.html#questions-for-further-investigation",
    "href": "lab/lab_1/lab1_template.html#questions-for-further-investigation",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "Questions for Further Investigation",
    "text": "Questions for Further Investigation\n\nAre there clusters of low confidence tracts within counties, and if so, do they correspond to known Indigenous reservations, migrant worker communities, and/or other communities that have been historically under-counted?\nHow do these income data reliability issues play a role in other variables like housing instability or unemployment? Would incorporating varied data sources minimize the risk of algorithmic bias in funding decisions?"
  },
  {
    "objectID": "lab/lab_1/lab1_template.html#submission-checklist",
    "href": "lab/lab_1/lab1_template.html#submission-checklist",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "Submission Checklist",
    "text": "Submission Checklist\nBefore submitting your portfolio link on Canvas:\n\nAll code chunks run without errors\nAll “[Fill this in]” prompts have been completed\nTables are properly formatted and readable\nExecutive summary addresses all four required components\nPortfolio navigation includes this assignment\nCensus API key is properly set\nDocument renders correctly to HTML\n\nRemember: Submit your portfolio URL on Canvas, not the file itself. Your assignment should be accessible at your-portfolio-url/labs/lab_1/your_file_name.html"
  }
]